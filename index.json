[{"authors":null,"categories":null,"content":"👋 Hi! I\u0026rsquo;m a third year Ph.D. candidate in EECS at U.C. Berkeley advised by Dr. Niloufar Salehi. My research applies human-computer interaction (HCI) methods to study machine learning and data systems. I\u0026rsquo;m currently thinking about how we can build trustworthy systems by aligning modeling assumptions with real world needs and goals, and prioritizing user agency. My current projects include developing more reliable machine translation systems for high-stakes domains like healthcare, analyzing data from a health tracking app to understand factors influencing adolescent menstrual health, and extracting and exploring patterns in messy text data. For Summer 2022, I will be an ML Research Intern on the Human-Centered Machine Intelligence Visualization team at Apple, supervised by Dr. Fred Hohman and Dr. Mary Beth Kery.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"👋 Hi! I\u0026rsquo;m a third year Ph.D. candidate in EECS at U.C. Berkeley advised by Dr. Niloufar Salehi. My research applies human-computer interaction (HCI) methods to study machine learning and data systems.","tags":null,"title":"Sam Robertson","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://samrobertson.netlify.com/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Samantha Robertson","Tonya Nguyen","Niloufar Salehi"],"categories":null,"content":"","date":1668211200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668211200,"objectID":"f3372a75fda3b41fedb0c55cc7a5688e","permalink":"https://samrobertson.netlify.com/publication/not_another_resource_map/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/not_another_resource_map/","section":"publication","summary":"Public school districts across the United States have implemented school choice systems that have the potential to improve underserved students' access to educational opportunities. However, research has shown that learning about and applying for schools can be extremely time-consuming and expensive, making it difficult for these systems to create more equitable access to resources in practice. A common factor surfaced in prior work is unequal access to information about the schools and enrollment process. In response, governments and non-profits have invested in providing more information about schools to parents, for instance, through detailed online dashboards. However, we know little about what information is actually useful for historically marginalized and underserved families. We conducted interviews with 10 low-income families and families of color to learn about the challenges they faced navigating an online school choice and enrollment system. We complement this data with four interviews with people who have supported families through the enrollment process in a wide range of roles, from school principal to non-profit staff (\"parent advocates\"). Our findings highlight the value of personalized support and trusting relationships to delivering relevant and helpful information. We contrast this against online information resources and dashboards, which tend to be impersonal, target a broad audience, and make strong assumptions about what parents should look for in a school without sensitivity to families' varying circumstances. We advocate for an assets-based design approach to information support in public school enrollment, which would ask how we can support the local, one-on-one support that community members already provide.","tags":["school choice","student assignment","mechanism design","social justice","social change","underserved communities"],"title":"Not Another School Resource Map: Meeting Underserved Families’ Information Needs Requires Trusting Relationships and Personalized Care","type":"publication"},{"authors":["Nikita Mehandru","Samantha Robertson","Niloufar Salehi"],"categories":null,"content":"","date":1655769600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655769600,"objectID":"04daee4ed7c8ce764da34536d4af5bbb","permalink":"https://samrobertson.netlify.com/publication/medical_mt/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/medical_mt/","section":"publication","summary":"Coming soon.","tags":[],"title":"Reliable and Safe Use of Machine Translation in Medical Settings","type":"publication"},{"authors":["Samantha Robertson","Mark Díaz"],"categories":null,"content":"","date":1655769600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655769600,"objectID":"a0a7273e1108018ada4008bda5c3835a","permalink":"https://samrobertson.netlify.com/publication/understanding_and_being_understood/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/understanding_and_being_understood/","section":"publication","summary":"Coming soon.","tags":[],"title":"Understanding and Being Understood: User Strategies for Identifying and Recovering From Mistranslations in Machine Translation-Mediated Chat","type":"publication"},{"authors":["Wesley Hanwen Deng","Nikita Mehandru","Samantha Robertson","Niloufar Salehi"],"categories":null,"content":"","date":1651276800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651276800,"objectID":"d1af60293bea143d418a0aea1d0d87f2","permalink":"https://samrobertson.netlify.com/publication/trait_22/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/trait_22/","section":"publication","summary":"Machine Translation (MT) has the potential to help people overcome language barriers and is widely used in high-stakes scenarios, such as in hospitals. However, in order to use MT reliably and safely, users need to understand when to trust MT outputs and how to assess the quality of often imperfect translation results. %More research is needed to study and design for building and calibrating trust in MT systems. In this paper, we discuss research directions to support users to calibrate trust in MT systems. We share findings from an empirical study in which we conducted semi-structured interviews with 20 clinicians to understand how they communicate with patients across language barriers, and if and how they use MT systems. Based on our findings, we advocate for empirical research on how MT systems are used in practice as an important first step to address the challenges in building appropriate trust between users and MT tools.","tags":[],"title":"Beyond General Purpose Machine Translation: The Need for Context-specific Empirical Research to Design for Appropriate User Trust","type":"publication"},{"authors":["Samantha Robertson","Tonya Nguyen","Niloufar Salehi"],"categories":null,"content":"","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"b6061c9d7d5826816f4f189a3d6499d2","permalink":"https://samrobertson.netlify.com/publication/modeling_assumptions_clash/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/publication/modeling_assumptions_clash/","section":"publication","summary":"Across the United States, a growing number of school districts are turning to matching algorithms to assign students to public schools. The designers of these algorithms aimed to promote values such as transparency, equity, and community in the process. However, school districts have encountered practical challenges in their deployment. In fact, San Francisco Unified School District voted to stop using and completely redesign their student assignment algorithm because it was frustrating for families and it was not promoting educational equity in practice. We analyze this system using a Value Sensitive Design approach and find that one reason values are not met in practice is that the system relies on modeling assumptions about families’ priorities, constraints, and goals that clash with the real world. These assumptions overlook the complex barriers to ideal participation that many families face, particularly because of socioeconomic inequalities. We argue that direct, ongoing engagement with stakeholders is central to aligning algorithmic values with real world conditions. In doing so we must broaden how we evaluate algorithms while recognizing the limitations of purely algorithmic solutions in addressing complex socio-political problems.","tags":["student assignment","mechanism design","value sensitive design"],"title":"Modeling Assumptions Clash with the Real World: Transparency, Equity, and Community Challenges for Student Assignment Algorithms","type":"publication"},{"authors":["Samantha Robertson","Wesley Hanwen Deng","Timnit Gebru","Margaret Mitchell","Daniel J. Liebling","Michal Lahav","Katherine Heller","Mark Díaz","Samy Bengio","Niloufar Salehi"],"categories":null,"content":"","date":1618876800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618876800,"objectID":"29267f5f1d318b3e61c4ea1c84435dda","permalink":"https://samrobertson.netlify.com/publication/hcmt/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/hcmt/","section":"publication","summary":"As people all over the world adopt machine translation (MT) to communicate across languages, there is increased need for affordances that aid users in understanding when to rely on automated translations. Identifying the information and interactions that will most help users meet their translation needs is an open area of research at the intersection of Human-Computer Interaction (HCI) and Natural Language Processing (NLP). This paper advances work in this area by drawing on a survey of users' strategies in assessing translations. We identify three directions for the design of translation systems that support more reliable and effective use of machine translation: helping users craft good inputs, helping users understand translations, and expanding interactivity and adaptivity. We describe how these can be introduced in current MT systems and highlight open questions for HCI and NLP research.","tags":["machine translation","human-centered design"],"title":"Three Directions for the Design of Human-Centered Machine Translation","type":"publication"},{"authors":["Samantha Robertson","Niloufar Salehi"],"categories":null,"content":"","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"ac9f026841593a10b77fb32448d9f591","permalink":"https://samrobertson.netlify.com/publication/limits_of_prefs/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/limits_of_prefs/","section":"publication","summary":"Emerging methods for participatory algorithm design have proposed collecting and aggregating individual stakeholder preferences to create algorithmic systems that account for those stakeholders' values. Using algorithmic student assignment as a case study, we argue that optimizing for individual preference satisfaction in the distribution of limited resources may actually inhibit progress towards social and distributive justice. Individual preferences can be a useful signal but should be expanded to support more expressive and inclusive forms of democratic participation.","tags":["mechanism design","student assignment","participatory design"],"title":"What If I Don't Like Any Of The Choices? The Limits of Preference Elicitation for Participatory Algorithm Design","type":"publication"},{"authors":null,"categories":[],"content":"  Each year, the World Health Organization releases a report with estimates of global immunization coverage. The report lots of visualizations of their data, and they release the data used for each visualization publicly. About a year ago, fresh out of Data Challenge Lab, the class offered by the Stanford Data Lab which I then TA’d a year later, I decided to practice some of my new vis skills by trying to replicate some of the visualizations in the 2016 report.\nI replicated three visualizations. Below are the comparisons of WHO’s vis against mine. All the code to create my plots is at the bottom of this post! I’m not fully convinced that the WHO visualizations are the most effective, for example two of them use redundant color, but for the challenge I tried to replicate them as faithfully as possible.\nBelow is the code for the three plots my way!\nFirst, I load the data and libraries and define some functions and constants for all three plots.\n# Libraries library(tidyverse) # Files data_dir \u0026lt;- \u0026quot;~/Data/who-immunizations/\u0026quot; file_global_mcv \u0026lt;- str_c(data_dir, \u0026quot;global_regional_coverage.csv\u0026quot;) file_weunic \u0026lt;- str_c(data_dir, \u0026quot;wuenic_master_07_06_2017.csv\u0026quot;) file_subnational \u0026lt;- str_c(data_dir, \u0026quot;subnational_06_29_2017.csv\u0026quot;) # Constants national_dtp3_countries \u0026lt;- c( \u0026quot;Pakistan\u0026quot;, \u0026quot;Syrian Arab Republic\u0026quot;, \u0026quot;Yemen\u0026quot;, \u0026quot;Iraq\u0026quot;, \u0026quot;Mali\u0026quot;, \u0026quot;Afghanistan\u0026quot;, \u0026quot;Haiti\u0026quot;, \u0026quot;Ethiopia\u0026quot;, \u0026quot;Democratic Republic of the Congo\u0026quot;, \u0026quot;Nigeria\u0026quot;, \u0026quot;Somalia\u0026quot; ) subnat_coverage_order \u0026lt;- c( \u0026quot;0 to 60%\u0026quot;, \u0026quot;60% to 70%\u0026quot;, \u0026quot;70% to 80%\u0026quot;, \u0026quot;90% to 95%\u0026quot;, \u0026quot;80% to 90%\u0026quot;, \u0026quot;95% to 100%\u0026quot;, \u0026quot;\u0026gt;100%\u0026quot; ) subnat_x_breaks \u0026lt;- c(seq(0, 100, by = 10), 400, 700, 1000) subnat_y_breaks \u0026lt;- c( 10, 500, 2000, 5000, 10000, 15000, seq(20000, 60000, by = 10000), 80000, 100000, 150000, seq(200000, 500000, by = 100000) ) subnat_size_breaks \u0026lt;- c(1, 10, 100, 1000, 10000, 100000, 300000) subnational_dtp3_labels \u0026lt;- c(\u0026quot;Dhaka\u0026quot;, \u0026quot;Lahore\u0026quot;, \u0026quot;Karachi\u0026quot;, \u0026quot;São Paulo\u0026quot;) # I picked the colors from the original plots using an online color picker color_mcv1 \u0026lt;- \u0026quot;#69bcd1\u0026quot; color_mcv2 \u0026lt;- \u0026quot;#d13f3e\u0026quot; color_mcv_refline \u0026lt;- \u0026quot;#367cc1\u0026quot; colors_dtp3_subnational \u0026lt;- c( \u0026quot;0 to 60%\u0026quot; = \u0026quot;#d5322f\u0026quot;, \u0026quot;60% to 70%\u0026quot; = \u0026quot;#f36d4a\u0026quot;, \u0026quot;70% to 80%\u0026quot; = \u0026quot;#fbad68\u0026quot;, \u0026quot;80% to 90%\u0026quot; = \u0026quot;#92cc64\u0026quot;, \u0026quot;90% to 95%\u0026quot; = \u0026quot;#6abc68\u0026quot;, \u0026quot;95% to 100%\u0026quot; = \u0026quot;#249752\u0026quot;, \u0026quot;\u0026gt;100%\u0026quot; = \u0026quot;#876086\u0026quot; ) # Helper functions global_mcv_y_labels \u0026lt;- function(vals) { # Add the percent sign only to the very top (100%) label if_else(vals == 100, str_c(vals, \u0026quot;%\u0026quot;), str_c(vals)) } subnat_x_labels \u0026lt;- function(vals) { # Add the percent sign to all but make the last element \u0026gt;X% vals \u0026lt;- scales::percent(vals, accuracy = 1, scale = 1) vals[length(vals)] \u0026lt;- str_c(\u0026quot;\u0026gt;\u0026quot;, vals[length(vals)]) vals } subnat_size_labels \u0026lt;- function(vals) { if_else(vals \u0026gt; 100, str_c(vals / 1000, \u0026quot;k\u0026quot;), str_c(vals)) } x_trans_trans \u0026lt;- function(x) { # Custom axis transformation for subnational dtp3 plot scales::trans_new( \u0026quot;x_trans\u0026quot;, function(x) if_else(x \u0026lt;= 100, x, 93.5 + (x/15)), function(x) if_else(x \u0026lt;= 100, x, (x - 93.5) * 15) ) } # ============================================================================== global_mcv \u0026lt;- read_csv(file_global_mcv) weunic \u0026lt;- read_csv(file_weunic) subnational \u0026lt;- read_csv(file_subnational) Global MCV Coverage This visualization shows the percentage of children worldwide receiving the MCV1 and MCV2 vaccines between 2000 and 2016. Vaccination coverage has been steadily increasing for both vaccines, though neither has reached the 90% target. MCV2 coverage is lower overall than MCV1 coverage, but is increasing at a faster rate.\nglobal_mcv %\u0026gt;% rename_all(str_to_lower) %\u0026gt;% filter( group == \u0026quot;Global\u0026quot;, vaccine %in% c(\u0026quot;mcv1\u0026quot;, \u0026quot;mcv2\u0026quot;), year \u0026gt;= 2000 ) %\u0026gt;% ggplot() + geom_line(aes(year, coverage, color = vaccine), size = 0.8) + geom_hline(yintercept = 90, color = color_mcv_refline, size = 0.8) + annotate( geom = \u0026quot;text\u0026quot;, x = 2008, y = 93, hjust = 0.5, label = \u0026quot;90% Vaccination Target\u0026quot;, color = color_mcv_refline, size = 3, fontface = \u0026quot;bold\u0026quot; ) + scale_x_continuous( breaks = seq(2000, 2016, by = 2) ) + scale_y_continuous( breaks = seq(0, 100, by = 20), limits = c(0, 100), labels = global_mcv_y_labels ) + scale_color_manual( values = c(\u0026quot;mcv1\u0026quot; = color_mcv1, \u0026quot;mcv2\u0026quot; = color_mcv2), labels = str_to_upper ) + theme_minimal() + theme( plot.title = element_text(face = \u0026quot;bold\u0026quot;), legend.justification = c(\u0026quot;right\u0026quot;, \u0026quot;top\u0026quot;), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), panel.background = element_rect(color = \u0026quot;grey60\u0026quot;), panel.grid.minor.y = element_line(color = \u0026quot;grey60\u0026quot;, size = 0.2), panel.grid.major.y = element_line(color = \u0026quot;grey60\u0026quot;, size = 0.2) ) + coord_cartesian( xlim = c(1999.5, 2016.5), ylim = c(0, 100), expand = FALSE, ) + labs( x = NULL, y = \u0026quot;Coverage\u0026quot;, color = NULL, title = \u0026quot;Global MCV1 and MCV2 Coverage\u0026quot; )  National DTP3 Coverage This visualization shows the change between 2010 and 2016 in DTP3 coverage in select countries. Like in the next visualization (subnational DTP3 coverage), color is encoding coverage in 2016, which is a redundant encoding. I did find that the graph is much more pleasing to the eye with the encoding, but is much simpler to understand without it, in my opinion.\nThere was a little bit of data manipulation to be done for this plot. The first step is filtering to the vaccine, countries and years we want. Then there is a mutate to create some helpful plotting variables. I created the tibble weunic_country_colors to keep track of which country should be which color.\nweunic \u0026lt;- weunic %\u0026gt;% rename_all(str_to_lower) %\u0026gt;% filter( year %in% c(2010, 2016), vaccine == \u0026quot;dtp3\u0026quot;, country %in% national_dtp3_countries ) %\u0026gt;% select(wuenic, year, country) %\u0026gt;% arrange(year, wuenic) %\u0026gt;% mutate( diff_to_next = lead(wuenic) - wuenic, ynudge = case_when( diff_to_next == 1 ~ -1, diff_to_next == 0 ~ -2, TRUE ~ 0 ), ypos = wuenic + ynudge ) weunic_country_colors \u0026lt;- weunic %\u0026gt;% filter(year == 2016) %\u0026gt;% mutate( color = case_when( wuenic \u0026lt; 60 ~ \u0026quot;red\u0026quot;, wuenic \u0026lt; 70 ~ \u0026quot;orange\u0026quot;, TRUE ~ \u0026quot;yellow\u0026quot; ) ) %\u0026gt;% select(country, color) weunic \u0026lt;- weunic %\u0026gt;% left_join(weunic_country_colors, by = \u0026quot;country\u0026quot;) Now the data is ready to plot! The code is long mostly because there are four labels for each country, and each needs to be a different type face and justification! The rest of the plot is quite basic.\nweunic %\u0026gt;% ggplot() + geom_point(aes(year, wuenic, color = color)) + geom_segment( aes( y = `2010`, yend = `2016`, color = color ), x = 2010, xend = 2016, data = select(weunic, country, year, wuenic) %\u0026gt;% spread(year, wuenic) %\u0026gt;% left_join(weunic_country_colors, by = \u0026quot;country\u0026quot;) ) + geom_text( # Label points with the numeric value aes( y = ypos, label = wuenic ), x = 2009.5, fontface = \u0026quot;bold\u0026quot;, data = filter(weunic, year == 2010) ) + geom_text( # Label points with country name aes( y = ypos, label = country ), x = 2009, hjust = 1, data = filter(weunic, year == 2010) ) + geom_text( aes( y = ypos, label = wuenic ), x = 2016.5, data = filter(weunic, year == 2016), fontface = \u0026quot;bold\u0026quot; ) + geom_text( aes( y = ypos, label = country ), x = 2017, hjust = 0, data = filter(weunic, year == 2016) ) + scale_x_continuous( breaks = c(2010, 2016), limits = c(2000, 2026), position = \u0026quot;top\u0026quot; ) + scale_color_manual( values = c( \u0026quot;red\u0026quot; = \u0026quot;#d5322f\u0026quot;, \u0026quot;orange\u0026quot; = \u0026quot;#f36d4a\u0026quot;, \u0026quot;yellow\u0026quot; = \u0026quot;#fbad68\u0026quot; ) ) + theme_minimal() + theme( panel.grid = element_blank(), axis.text.y = element_blank(), axis.text.x = element_text( color = \u0026quot;black\u0026quot;, size = 16, face = \u0026quot;bold\u0026quot; ), plot.title = element_text( size = 16, face = \u0026quot;bold\u0026quot;, hjust = 0.5 ), legend.position = \u0026quot;none\u0026quot; ) + labs( x = NULL, y = NULL, title = \u0026quot;Trends in DTPcv3 Coverage since\\n2010 for Selected Countries\u0026quot; )  Subnational DTP3 Coverage This visualization shows the 2016 Coverage rate and number of surviving infants at the subnational level across the world. I was struck by the aesthetics of the plot, however I am torn as to whether the redundant encoding of size and color is distracting or not. I have been taught that all redundant information should be excluded, and quite clearly each variable is encoded in two different aesthetics, however I do think the colors, at least, help to differentiate and draw the eye. Regardless, the plot was quite a challenge to replicate so I kept the redundancy just for fun.\nsubnational %\u0026gt;% filter( annum == 2016, Vaccode == \u0026quot;DTP3\u0026quot;, !is.na(Admin2) ) %\u0026gt;% mutate( color = case_when( Coverage \u0026lt;= 60 ~ \u0026quot;0 to 60%\u0026quot;, Coverage \u0026lt;= 70 ~ \u0026quot;60% to 70%\u0026quot;, Coverage \u0026lt;= 80 ~ \u0026quot;70% to 80%\u0026quot;, Coverage \u0026lt;= 90 ~ \u0026quot;80% to 90%\u0026quot;, Coverage \u0026lt;= 95 ~ \u0026quot;90% to 95%\u0026quot;, Coverage \u0026lt;= 100 ~ \u0026quot;95% to 100%\u0026quot;, TRUE ~ \u0026quot;\u0026gt;100%\u0026quot; ), color = factor(color, levels = subnat_coverage_order, ordered = TRUE), Coverage = if_else(Coverage \u0026lt; 1000, Coverage, 1000), label = if_else(Admin2 %in% subnational_dtp3_labels, Admin2, \u0026quot;\u0026quot;) ) %\u0026gt;% sample_frac() %\u0026gt;% ggplot() + geom_point( aes( Coverage, Denominator, size = Denominator, fill = color ), shape = 21, color = \u0026quot;white\u0026quot;, stroke = 0.25 ) + ggrepel::geom_text_repel( aes( Coverage, Denominator, label = label ), point.padding = 0.5, min.segment.length = 1 ) + scale_x_continuous( trans = \u0026quot;x_trans\u0026quot;, breaks = subnat_x_breaks, labels = subnat_x_labels, position = \u0026quot;top\u0026quot; ) + scale_y_continuous( trans = \u0026quot;sqrt\u0026quot;, breaks = subnat_y_breaks, labels = scales::unit_format(unit = \u0026quot;\u0026quot;, scale = 1, sep = \u0026quot;\u0026quot;), position = \u0026quot;right\u0026quot;, limits = c(10, 500000) ) + scale_size( range = c(1, 10), breaks = subnat_size_breaks, labels = subnat_size_labels, guide = guide_legend( title.position = \u0026quot;top\u0026quot;, nrow = 1, override.aes = list(fill = \u0026quot;black\u0026quot;, color = \u0026quot;black\u0026quot;), label.position = \u0026quot;bottom\u0026quot;, label.hjust = 0.5 ) ) + scale_fill_manual( values = colors_dtp3_subnational, guide = guide_legend( title.position = \u0026quot;top\u0026quot;, ncol = 1, override.aes = list(shape = 22, size = 5), reverse = TRUE ) ) + labs( x = \u0026quot;DTP3 Coverage\u0026quot;, y = \u0026quot;Surviving Infants\u0026quot;, title = \u0026quot;DTPcv3 Reported Coverage by District\u0026quot;, fill = \u0026quot;Coverage\u0026quot;, size = \u0026quot;Surviving Infants\u0026quot; ) + theme_minimal() + theme( axis.title.x = element_text(face = \u0026quot;bold\u0026quot;, hjust = 0), axis.title.y = element_text(face = \u0026quot;bold\u0026quot;, hjust = 0), legend.position = \u0026quot;bottom\u0026quot;, legend.title = element_text(face = \u0026quot;bold\u0026quot;), legend.justification = \u0026quot;left\u0026quot;, plot.title = element_text(face = \u0026quot;bold\u0026quot;), panel.grid.minor = element_blank() ) + coord_cartesian( xlim = c(10, 1000), ylim = c(0, 500000), expand = FALSE, clip = \u0026quot;off\u0026quot; )  ","date":1565308800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565308800,"objectID":"dd08d9566fabafc6365a60f91b12ef6d","permalink":"https://samrobertson.netlify.com/post/2019-08-09-who-immunizations/","publishdate":"2019-08-09T00:00:00Z","relpermalink":"/post/2019-08-09-who-immunizations/","section":"post","summary":"Each year, the World Health Organization releases a report with estimates of global immunization coverage. The report lots of visualizations of their data, and they release the data used for each visualization publicly.","tags":["R","data-visualization","tidyverse"],"title":"Replicating WHO Visualizations of Global Immunization Coverage","type":"post"},{"authors":null,"categories":[],"content":"  This week’s RWeekly digest included an awesome dataset from the World Bank that documents the percentage of women in lower house parliament across the globe from 1997 to 2018. The dataset is nearly complete and also includes summary statistics for numerous geographic aggregations.\nAll of my code to process and explore the data is available on my GitHub. There’s lots of interesting things to look at in this data, so I will leave most of the boring stuff out of this post.\nTo get a sense of the World Bank data, here are the top 10 and bottom 10 countries in 2018 in terms of percentage of parliament made up of women.\nwip %\u0026gt;% filter(year == 2018) %\u0026gt;% top_n(n = 10, wt = prop_women_seats) %\u0026gt;% arrange(desc(prop_women_seats)) %\u0026gt;% knitr::kable(caption = \u0026quot;Top 10 Countries with the largest proportion of women in their parliament in 2018\u0026quot;)  Table 1: Top 10 Countries with the largest proportion of women in their parliament in 2018  country_name country_code year prop_women_seats    Rwanda RWA 2018 61.3  Cuba CUB 2018 53.2  Bolivia BOL 2018 53.1  Mexico MEX 2018 48.2  Grenada GRD 2018 46.7  Namibia NAM 2018 46.2  Sweden SWE 2018 46.1  Nicaragua NIC 2018 45.7  Costa Rica CRI 2018 45.6  South Africa ZAF 2018 42.3    wip %\u0026gt;% filter(year == 2018) %\u0026gt;% top_n(n = 10, wt = -prop_women_seats) %\u0026gt;% arrange(prop_women_seats) %\u0026gt;% knitr::kable(caption = \u0026quot;Bottom 10 Countries with the smallest proportion of women in their parliament in 2018\u0026quot;)  Table 2: Bottom 10 Countries with the smallest proportion of women in their parliament in 2018  country_name country_code year prop_women_seats    Micronesia, Fed. Sts. FSM 2018 0.0  Papua New Guinea PNG 2018 0.0  Vanuatu VUT 2018 0.0  Yemen, Rep. YEM 2018 0.0  Oman OMN 2018 1.2  Haiti HTI 2018 2.5  Kuwait KWT 2018 3.1  Solomon Islands SLB 2018 4.0  Lebanon LBN 2018 4.7  Thailand THA 2018 5.3    Only 3 countries had over half women in their parliament in 2018! The top 10 are still all over 40%, which seems encouraging! Less encouragingly, four nations still had 0 women in the lower house of parliament in 2018.\nGlobal Trends in Female Representation Conveniently, the dataset has a precalculated global aggregate statistic.\nwip %\u0026gt;% filter(country_name == \u0026quot;World\u0026quot;) %\u0026gt;% ggplot(aes(year, prop_women_seats)) + geom_point() + geom_line() + scale_x_continuous( breaks = seq(1998, 2018, by = 2), minor_breaks = FALSE ) + scale_y_continuous(labels = scales::percent_format(accuracy = 1, scale = 1)) + theme_minimal() + labs( title = \u0026quot;There has been a constant upward trend globally since 1997\u0026quot;, x = NULL, y = \u0026quot;Percentage of parliament seats held by women\u0026quot; ) It is encouraging to see that female representation has increased every year when we look at the whole world aggregated.\nBy region regions \u0026lt;- c( \u0026quot;East Asia \u0026amp; Pacific\u0026quot;, \u0026quot;Europe \u0026amp; Central Asia\u0026quot;, \u0026quot;Latin America \u0026amp; Caribbean\u0026quot;, \u0026quot;Middle East \u0026amp; North Africa\u0026quot;, \u0026quot;Sub-Saharan Africa\u0026quot;, \u0026quot;North America\u0026quot;, \u0026quot;South Asia\u0026quot; ) wip %\u0026gt;% filter(country_name %in% regions) %\u0026gt;% drop_na(prop_women_seats) %\u0026gt;% ggplot(aes(year, prop_women_seats, color = country_name)) + geom_line(size = 1) + geom_point(size = 1) + ggrepel::geom_text_repel( aes(label = country_name), data = . %\u0026gt;% group_by(country_name) %\u0026gt;% top_n(1, wt = year), nudge_x = 0.25, direction = \u0026quot;y\u0026quot;, hjust = 0 ) + scale_x_continuous( breaks = seq(1998, 2018, 2), minor_breaks = NULL, limits = c(1997, 2028) ) + scale_y_continuous(labels = scales::percent_format(accuracy = 1, scale = 1)) + guides(color = \u0026quot;none\u0026quot;) + theme_minimal() + labs( x = NULL, y = \u0026quot;Percentage of parliament seats held by women\u0026quot;, title = \u0026quot;All regions but South Asia have had increasing representation since 1997\u0026quot;, subtitle = \u0026quot;Latin America \u0026amp; Caribbean and Middle East \u0026amp; North Africa have seen large incerases\u0026quot; ) Notably, Latin America \u0026amp; the Caribbean went from the fourth leading region in terms of female representation in the late 1990s to the leading region by a relatively significant margin by 2014. The Middle East \u0026amp; North Africa, though still lagging behind the rest of the world, also has experienced a marked increase since 1997. Interestingly, South Asia is the only region that has shown a decrease, with representation plateauing in 2009, and then beginning to decrease.\n By income level Another interesting aggregation is by income level of the countries.\norder \u0026lt;- c( \u0026quot;High income\u0026quot;, \u0026quot;Upper middle income\u0026quot;, \u0026quot;Middle income\u0026quot;, \u0026quot;Lower middle income\u0026quot;, \u0026quot;Low income\u0026quot; ) wip %\u0026gt;% filter(country_name %in% order) %\u0026gt;% mutate(country_name = factor(country_name, levels = order, ordered = TRUE)) %\u0026gt;% drop_na(prop_women_seats) %\u0026gt;% ggplot(aes(year, prop_women_seats, color = country_name)) + geom_line(aes(group = country_name), color = \u0026quot;white\u0026quot;, size = 2) + geom_point(aes(group = country_name), color = \u0026quot;white\u0026quot;, size = 1) + geom_point(size = 1) + geom_line(size = 1) + ggrepel::geom_text_repel( aes(label = country_name), data = . %\u0026gt;% group_by(country_name) %\u0026gt;% top_n(1, wt = year), nudge_x = 0.25, direction = \u0026quot;y\u0026quot;, hjust = 0, color = \u0026quot;grey30\u0026quot; ) + scale_x_continuous( breaks = seq(1998, 2018, 2), minor_breaks = NULL, limits = c(1997, 2025) ) + scale_y_continuous(labels = scales::percent_format(accuracy = 1, scale = 1)) + guides(color = \u0026quot;none\u0026quot;) + theme_minimal() + labs( title = \u0026quot;Low income countries outperform lower middle income countries\u0026quot;, x = NULL, y = \u0026quot;Percentage of parliament seats held by women\u0026quot; ) Unsurprisingly, based on the previous two plots, representation is increasing over time at all income levels. There is something very striking about this plot, though. Representation has been higher with higher income, with the obvious exception of low income regions. Representation in low income regions has been higher than in lower middle income regions every year recorded, and in three different years has been second only to high income regions.\n By country It is really difficult to look at the trend of all nations at once, given how many there are. We can visualize the most recent data across the globe by looking at a map of the world with data from 2018.\nmidpoint \u0026lt;- wip %\u0026gt;% filter(year == 2018) %\u0026gt;% semi_join(world %\u0026gt;% select(country_code = iso_a3)) %\u0026gt;% summarize(median_prop_women = median(prop_women_seats, na.rm = TRUE)) %\u0026gt;% pull(median_prop_women) ## Joining, by = \u0026quot;country_code\u0026quot; world %\u0026gt;% left_join( wip %\u0026gt;% filter(year == 2018), by = c(\u0026quot;iso_a3\u0026quot; = \u0026quot;country_code\u0026quot;) ) %\u0026gt;% ggplot() + geom_sf( aes(fill = prop_women_seats), color = \u0026quot;grey20\u0026quot;, size = 0.1 ) + scale_fill_gradient( low = \u0026quot;white\u0026quot;, high = \u0026quot;#01665e\u0026quot;, labels = scales::percent_format(accuracy = 1, scale = 1) ) + coord_sf(datum = NA) + guides( fill = guide_colorbar( barwidth = 8, barheight = 0.5 ) ) + theme_void() + theme( legend.position = \u0026quot;top\u0026quot;, legend.title.align = 1 ) + labs(fill = \u0026quot;Proportion of seats\\nheld by women\u0026quot;)   Case study: Rwanda Though it’s hard to see from the map, at the very beginning we noticed that Rwanda had the highest female representation in its parliament in 2018, at over 60%! Looking into the politics there a bit more, I found that they introduced a quota system in 2003 that required 30% of the parliament to be made up of women. Looking at the data, there is a clear increase at the time this policy began.\nwip %\u0026gt;% drop_na(prop_women_seats) %\u0026gt;% filter(country_name == \u0026quot;Rwanda\u0026quot;) %\u0026gt;% ggplot(aes(year, prop_women_seats)) + geom_hline(yintercept = 50, size = 2, color = \u0026quot;grey80\u0026quot;) + geom_vline(xintercept = 2003, size = 1, color = \u0026quot;#b2182b\u0026quot;) + geom_line() + geom_point() + annotate( geom = \u0026quot;text\u0026quot;, x = 2003.25, y = 40, label = \u0026quot;30% quota\\nintroduced\\nin 2003\u0026quot;, hjust = 0, color = \u0026quot;grey40\u0026quot; ) + scale_x_continuous( breaks = seq(1998, 2018, 2), minor_breaks = NULL ) + scale_y_continuous(labels = scales::percent_format(accuracy = 1, scale = 1)) + theme_minimal() + labs( title = \u0026quot;Rwanda reached almost 50/50 representation after the introduction of a quota\u0026quot;, subtitle = \u0026quot;Representation continued to increase even 10 years later\u0026quot;, x = NULL, y = \u0026quot;Percentage of parliament seats held by women\u0026quot; )  Quota Systems The case study of Rwanda made me think more about quotas: how effective are they? where have they been implemented? Conveniently, the Institute for Democracy and Electoral Assistance (IDEA) has a public dataset of the types of quotas implemented all over the world! The only downside is that the database doesn’t include the year the quota was introduced. This is something that could be collated manually but we can work without for now.\nThere are three types of “quotas” in the dataset, explicit quotas about the number or fraction of seats to be held by women, a reserved seats system where certain seats must be held by women, and voluntary systems where some parties elect to hold themselves to a quota but none exists in law. We can visualize how these systems are implemented around the world with a map.\ntype_order \u0026lt;- quotas %\u0026gt;% count(quota_type, sort = TRUE) %\u0026gt;% pull(quota_type) world %\u0026gt;% left_join( quotas %\u0026gt;% mutate( quota_type = factor( quota_type, levels = type_order, ordered = TRUE ) ), by = c(\u0026quot;iso_a3\u0026quot; = \u0026quot;country_code\u0026quot;) ) %\u0026gt;% ggplot() + geom_sf(aes(fill = quota_type), color = \u0026quot;white\u0026quot;, size = 0.1) + scale_fill_brewer( type = \u0026quot;qual\u0026quot;, palette = \u0026quot;Dark2\u0026quot;, na.value = \u0026quot;grey80\u0026quot; ) + theme_minimal() + theme(legend.position = \u0026quot;top\u0026quot;) + coord_sf(datum = NA) + labs(x = NULL, y = NULL, fill = \u0026quot;Quota Type\u0026quot;) We can see that South \u0026amp; Central America have almost completely adopted quotas. As we noticed above, this region has had particularly notable improvement in female representation since 1997.\nNow to make any causal claims about quotas and representation trends would need much more careful analysis, so I should emphasize I am not trying to do that. There are a couple of simple questions we could answer with this data, though.\nDo the countries with the biggest increase in representation from 1997 to 2018 also have quota systems in place?  differences \u0026lt;- wip_quotas %\u0026gt;% filter(year %in% c(1997, 2018)) %\u0026gt;% spread(key = year, value = prop_women_seats) %\u0026gt;% mutate( difference = `2018` - `1997`, quota_type = if_else(is.na(quota_type), \u0026quot;None\u0026quot;, quota_type) ) %\u0026gt;% drop_na(difference) differences %\u0026gt;% top_n(n = 10, wt = difference) %\u0026gt;% arrange(desc(difference)) %\u0026gt;% select(country_name, quota_type, difference) %\u0026gt;% knitr::kable(caption = \u0026quot;The countries with the biggest increase in percentage of parliament seats held by women from 1997 to 2018\u0026quot;)  Table 3: The countries with the biggest increase in percentage of parliament seats held by women from 1997 to 2018  country_name quota_type difference    Rwanda Reserved seats 44.2  Ethiopia Voluntary 36.8  North Macedonia Quota 35.0  Nicaragua Quota 34.9  Ecuador Quota 34.3  Mexico Quota 34.0  Cuba None 30.4  Senegal Quota 30.1  Costa Rica Quota 29.8  Nepal Reserved seats 29.3    In fact only two of the top 10 countries by increase 1997-2018 did not have some form of legally binding quota system in place.\nDid countries with quota systems in place see larger year-to-year jumps than those without?  largest_jumps \u0026lt;- wip_quotas %\u0026gt;% group_by(country_code) %\u0026gt;% arrange(year) %\u0026gt;% mutate( jump = lag(prop_women_seats) - prop_women_seats, quota_type = if_else(is.na(quota_type), \u0026quot;None\u0026quot;, quota_type) ) %\u0026gt;% drop_na(jump) %\u0026gt;% summarize( largest_jump = max(jump), quota_type = first(quota_type) ) %\u0026gt;% filter( quota_type != \u0026quot;Funding incentives\u0026quot; # only one country ) ## `summarise()` ungrouping output (override with `.groups` argument) median_largest_jump \u0026lt;- largest_jumps %\u0026gt;% summarize(med = median(largest_jump)) %\u0026gt;% pull(med) largest_jumps %\u0026gt;% ggplot(aes(quota_type, largest_jump)) + geom_hline(yintercept = median_largest_jump, size = 2, color = \u0026quot;white\u0026quot;) + geom_violin(draw_quantiles = 0.5) + scale_y_continuous(labels = scales::percent_format(accuracy = 1, scale = 1)) + labs( x = \u0026quot;Quota type\u0026quot;, y = \u0026quot;Largest one-year jump in female representation from 1997 to 2018\u0026quot;, title = \u0026quot;More countries with quota systems saw large year-to-year jumps\\nin female representation\u0026quot;, subtitle = \u0026quot;Though some very large jumps occurred in countries without quotas\u0026quot; ) To make this plot, I calculated the largest jump in percentage of seats held by women from one year to the next for each country. The distribution of these jumps by quota system is then plotted as a violin plot. The white reference line shows the median largest jump size across all countries. Each line within a violin plot shows the median largest jump size for countries with that type of quota system in place.\nTwo things are clear:\n More than 50% of countries with some kind of quota system experienced a larger jump than the median largest jump in countries with no quota system at all. Some countries with no quota system experienced extremely large jumps from one year to the next. Clearly quotas are not necessary to achieve this.  Side note: since I was curious, I looked up that enormous outlier. It’s Andorra and they had an election in 2011 where 15 women were elected making them the first country in Europe to have a majority female parliament.   Like I said before, I am being careful not to make any causal claims here. Clearly, representation can be increased with or without quotas. Exploring these datasets has been lots of fun, and there are definitely some very positive examples that give hope for a more equal future!\n ","date":1565136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565136000,"objectID":"ad91a88c6bb232a0fe658ecfd2985d09","permalink":"https://samrobertson.netlify.com/post/2019-08-07-womeninparliament/","publishdate":"2019-08-07T00:00:00Z","relpermalink":"/post/2019-08-07-womeninparliament/","section":"post","summary":"This week’s RWeekly digest included an awesome dataset from the World Bank that documents the percentage of women in lower house parliament across the globe from 1997 to 2018.","tags":["R","data-visualization","tidyverse"],"title":"Women in Parliament Worldwide","type":"post"},{"authors":null,"categories":[],"content":"  It’s not often I see a cool data project focused on Australia, and in particular Australian politics, so I was especially excited to see freerangestats’ exploration of the 2016 Australian Election Study featured in RWeekly this week! The RWeekly email included this visualization, showing the responses to 6 questions about Australia’s parliamentary system, organized by party preference for Senate in the 2013 Federal Election.\nAt first, I was excited to see where voters for my party came in relative to other voters in parliamentary trivia, but then… how can I even compare? I quickly realized that I have many qualms with this plot.\nFirst, it takes some hunting to find the correct answers to each question (they’re listed in the subtitle), and once you’ve found them you have to go through six facets and match responses to answers. The plot shows the proportion of respondents who answered True, False or Don’t Know to each question. In my opinion, it would be far more intuitive to show only what we really care about: who was right!\nThen there’s the choice of the stacked bar chart. Firstly, placing the “Don’t Know” responses at the middle, centered at 0, makes it almost impossible to see the percentages of “True” and “False” respondents, about whom we likely care far more. Secondly, the choice to make “False” go in the “negative” (labelled positive) direction on the axis, as well as the color choice, makes me intuitively assume that the orange indicates incorrect answers and green indicates correct.\nFinally, what set me off in the first place: we can’t compare between parties! The orientation of the facets makes it very difficult to compare in the horizontal direction, even if the bars did all start at zero.\nHere’s my proposed improvement on the visualization from freerangestats:\nIt looks from this plot like the Greens voters have outdone everyone across the board, followed by voters for the coalition. We shouldn’t draw any conclusions too quickly though, keep reading to see the code and explore how education levels influence Australian voters’ knowledge of their parliament.\nImporting and Wrangling the Data # Libraries # ========= library(tidyverse) library(haven) # Constants # ========= FILE_DATA \u0026lt;- \u0026quot;~/Data/aus-election-poll/aes2016.sas7bdat\u0026quot; QUESTION_ABBRS \u0026lt;- c( \u0026quot;federation_1901\u0026quot;, \u0026quot;prop_rep\u0026quot;, \u0026quot;time_between_elections\u0026quot;, \u0026quot;constitution\u0026quot;, \u0026quot;deposit\u0026quot;, \u0026quot;num_members_hrp\u0026quot; ) QUESTION_LABELS \u0026lt;- c( \u0026quot;Australia became a\\nfederation in 1901\\n(True)\u0026quot;, \u0026quot;The Senate election is\\nbased on proportional representation\\n(True)\u0026quot;, \u0026quot;The longest time allowed between\\nFederal elections for the House\\nof Representatives is four years\\n(False)\u0026quot;, \u0026quot;The Constitution can only be\\nchanged by the High Court\\n(False)\u0026quot;, \u0026quot;No-one may stand for Federal\\nparliament unless they pay a deposit\\n(True)\u0026quot;, \u0026quot;There are 75 members of\\nthe House of Representatives\\n(False)\u0026quot; ) QUESTION_LABELS_SHORT \u0026lt;- c( \u0026quot;Federation\u0026quot;, \u0026quot;Proportional Representation\u0026quot;, \u0026quot;Years Between Elections\u0026quot;, \u0026quot;Changing the Constitution\u0026quot;, \u0026quot;Deposit to Stand\\nfor Federal Election\u0026quot;, \u0026quot;Number of Members\\nin the House of Reps\u0026quot; ) PARTY_LEVELS \u0026lt;- c( \u0026quot;Coalition\u0026quot;, \u0026quot;Labor Party (ALP)\u0026quot;, \u0026quot;Greens\u0026quot;, \u0026quot;Other (incl. no vote)\u0026quot; ) PARTY_COLORS \u0026lt;- c(\u0026quot;#1b4f9c\u0026quot;, \u0026quot;#e43340\u0026quot;, \u0026quot;#009c3d\u0026quot;, \u0026quot;grey60\u0026quot;) EDUCATION_LEVELS \u0026lt;- c( \u0026quot;some secondary\u0026quot;, \u0026quot;secondary\u0026quot;, \u0026quot;trade\u0026quot;, \u0026quot;university\u0026quot; ) EDUCATION_LABELS \u0026lt;- c( \u0026quot;Some secondary school\\nor less\u0026quot;, \u0026quot;Secondary school only\u0026quot;, \u0026quot;Trade Qualification\\nor other Diploma\u0026quot;, \u0026quot;Bachelor\u0026#39;s Degree\\nor higher\u0026quot; ) # Functions # ========= recode_truefalse \u0026lt;- function(x, answer) { recode( x, `1` = TRUE, `2` = FALSE, .default = NA ) %in% answer } recode_party \u0026lt;- function(x) { recode( x, `1` = \u0026quot;Coalition\u0026quot;, `2` = \u0026quot;Labor Party (ALP)\u0026quot;, `3` = \u0026quot;Coalition\u0026quot;, `4` = \u0026quot;Greens\u0026quot;, `997` = NA_character_, `998` = NA_character_, .default = \u0026quot;Other (incl. no vote)\u0026quot; ) } recode_01 \u0026lt;- function(x) { if_else(x %in% 997:999, NA_real_, x) } import_vars \u0026lt;- list( weight = list(var = \u0026quot;wt_enrol\u0026quot;, fun = identity), senate_vote = list(var = \u0026quot;B9_2\u0026quot;, fun = recode_party), schooling = list(var = \u0026quot;G1\u0026quot;, fun = recode_01), tertiary = list(var = \u0026quot;G3\u0026quot;, fun = recode_01), federation_1901 = list(var = \u0026quot;F10_1\u0026quot;, fun = function(.) recode_truefalse(., TRUE)), num_members_hrp = list(var = \u0026quot;F10_2\u0026quot;, fun = function(.) recode_truefalse(., FALSE)), constitution = list(var = \u0026quot;F10_3\u0026quot;, fun = function(.) recode_truefalse(., FALSE)), prop_rep = list(var = \u0026quot;F10_4\u0026quot;, fun = function(.) recode_truefalse(., TRUE)), deposit = list(var = \u0026quot;F10_5\u0026quot;, fun = function(.) recode_truefalse(., TRUE)), time_between_elections = list(var = \u0026quot;F10_6\u0026quot;, fun = function(.) recode_truefalse(., FALSE)) ) The first step is to read in and wrangle the data. I downloaded the data in SAS format, so I use haven::read_sas to read the raw data. The list import_vars specifies the columns we would like to keep, the column names we would like to assign, and the functions we would like to apply to recode the survey response variables to a readable format.\nThere are many encodings in the survey data that should be recoded. For example, AES encodes “Item skipped” and “Does not apply”, responses we would like to encode as NA, as numbers 997 and 999. I also define functions to redefine the “True”/“False”/“Don’t Know” responses into logical vectors representing whether the respondent answered correctly, and to give names to the political parties. I chose to collapse the Liberal Party and the National (Country) Party into the Coalition, and drop One Nation to make the visualizations easier to digest.\nI define my own education variable based on responses to two questions: “How old were you when you left secondary school?” and “Have you obtained a trade qualification, a degree or a diploma, or any other qualification since leaving school?”\ndf \u0026lt;- read_sas(data_file = FILE_DATA) true_false \u0026lt;- import_vars %\u0026gt;% map_dfc(~ .$fun(pull(df, .$var))) %\u0026gt;% mutate( education = case_when( schooling \u0026gt; 1 ~ \u0026quot;some secondary\u0026quot;, tertiary == 1 ~ \u0026quot;secondary\u0026quot;, tertiary %in% c(2, 3) ~ \u0026quot;university\u0026quot;, tertiary %in% c(4, 5, 6, 7) ~ \u0026quot;trade\u0026quot;, TRUE ~ NA_character_ ), education = factor( education, levels = EDUCATION_LEVELS, labels = EDUCATION_LABELS, ordered = TRUE ), senate_vote = factor(senate_vote, levels = PARTY_LEVELS) ) %\u0026gt;% select(-schooling, -tertiary)  Visualizing Responses by Party Now that the data has been cleaned up, I can create my version of the freerangestats visualization.\nresponses \u0026lt;- true_false %\u0026gt;% drop_na() %\u0026gt;% select(-weight, -education) %\u0026gt;% group_by(senate_vote) %\u0026gt;% summarise_all(mean, na.rm = TRUE) %\u0026gt;% gather( key = \u0026quot;question\u0026quot;, value = \u0026quot;prop_correct\u0026quot;, -senate_vote ) %\u0026gt;% mutate( question = factor( question, levels = QUESTION_ABBRS, labels = QUESTION_LABELS ) ) responses %\u0026gt;% ggplot( aes( reorder(question, -prop_correct), prop_correct, color = senate_vote ) ) + geom_hline(yintercept = 0.5, color = \u0026quot;white\u0026quot;, size = 2) + geom_line(aes(group = senate_vote)) + geom_point() + scale_color_manual( breaks = PARTY_LEVELS, values = PARTY_COLORS ) + scale_y_continuous( breaks = seq(0, 1, by = 0.1), labels = scales::percent_format(accuracy = 1) ) + theme( axis.text.x = element_text(size = 7), legend.position = \u0026quot;top\u0026quot;, legend.title = element_blank() ) + labs( title = \u0026quot;Australians\u0026#39; Knowledge of Constitutional Issues\u0026quot;, subtitle = \u0026quot;By Senate Vote in the 2013 Federal Election\u0026quot;, caption = \u0026quot;Source: Australian Election Study 2016\u0026quot;, x = \u0026quot;True/False Question (Answer)\u0026quot;, y = \u0026quot;Percentage of respondents who answered correctly\u0026quot; ) I think this plot is an improvement for a few reasons:\n We can very easily compare between parties, and can very quickly identify parties by their official colors\n We can quickly see the percentage of correct respondents\n We can see which questions were easier and which were more difficult for the respondents\n The answers are listed with the questions\n  There is some information lost, for example we can no longer see how many people said they didn’t know the answer, and it is much more difficult to figure out the raw responses. However, in my opinion this is far less important information in this context.\n Controlling for Education Level The AES gives us lots of details about the respondents including their education level. Although the plot above appears to indicate that Greens voters know the most about the parliamentary system, I was wary to jump to this conclusion without controlling for the level of education of the voters.\nTo make inferences about the enrolled population, we need to use the provided weights. Then we are able to calculate the proportion of the electorate and the proportion of voters for each of the Coalition, ALP and the Greens at each level of education.\ntotal_ed_props \u0026lt;- true_false %\u0026gt;% drop_na() %\u0026gt;% count(education, wt = weight) %\u0026gt;% mutate(prop_educated = n / sum(n), group = \u0026quot;All respondents\u0026quot;) ed_props_by_party \u0026lt;- true_false %\u0026gt;% drop_na() %\u0026gt;% filter(senate_vote != \u0026quot;Other (incl. no vote)\u0026quot;) %\u0026gt;% count(senate_vote, education, wt = weight) %\u0026gt;% group_by(senate_vote) %\u0026gt;% mutate(prop_educated = n / sum(n)) %\u0026gt;% ungroup() Plotting these proportions shows dramatic disparities:\ned_props_by_party %\u0026gt;% ggplot(aes(education, prop_educated)) + geom_line( aes(group = group), color = \u0026quot;grey60\u0026quot;, data = total_ed_props ) + geom_point(color = \u0026quot;grey60\u0026quot;, data = total_ed_props) + geom_line(aes(group = senate_vote, color = senate_vote)) + geom_point(aes(color = senate_vote)) + scale_y_continuous( breaks = seq(0, 0.5, by = 0.1), labels = scales::percent_format(accuracy = 1) ) + scale_color_manual( breaks = PARTY_LEVELS, values = PARTY_COLORS ) + theme( legend.position = \u0026quot;top\u0026quot;, axis.text.x = element_text(size = 8) ) + labs( title = \u0026quot;The highly educated are far overrepresented amongst Greens voters\u0026quot;, subtitle = \u0026quot;Over 55% of Greens voters are university graduates, compared to 37% of the\\n enrolled population (shown in grey)\u0026quot;, x = NULL, y = \u0026quot;Percentage of voters by party\\nweighted to match enrolled population\u0026quot;, color = NULL, caption = \u0026quot;Source: Australian Election Study 2016\u0026quot; ) As we see in the plot above, university graduates are far overrepresented amongst Greens voters, while voters for Labor and the Coalition are reflective of national trends in education levels.\nTo understand whether educational differences account for the variation in performance on the True/False questions, we need to do some further exploration. To simplify this, I decided to calculate a score for each respondent. A simple and interpretable score is the proportion of correct answers to the 6 True/False questions.\nscores \u0026lt;- true_false %\u0026gt;% drop_na() %\u0026gt;% mutate( frac_correct = (federation_1901 + prop_rep + time_between_elections + constitution + deposit + num_members_hrp) / 6 ) We can then visualize the distribution of scores at each education level.\nscores %\u0026gt;% ggplot(aes(education, frac_correct)) + geom_hline(yintercept = 0.5, size = 2, color = \u0026quot;white\u0026quot;) + geom_boxplot(varwidth = TRUE) + scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + labs( x = \u0026quot;Highest Level of Education Attained\u0026quot;, y = \u0026quot;Percentage of questions answered correctly (of 6 total)\u0026quot;, title = \u0026quot;Median Performance Increases with Education Level\u0026quot;, subtitle = \u0026quot;But performance varies widely at all levels\u0026quot;, caption = \u0026quot;Source: Australian Election Study 2016\u0026quot; ) Despite the wide variation at every level of education, it does appear that university graduates performed the best on the multiple choice questions, with the top half of respondents with a Bachelor’s degree or higher getting at least half of the questions correct.\nFinally, we can visualize the joint distribution of performance across the six questions, across the levels of education and across the party preferences. I chose to leave out those with less than a secondary school education, as this was a very small sample.\nresponses_with_ed \u0026lt;- true_false %\u0026gt;% drop_na() %\u0026gt;% select(-weight) %\u0026gt;% filter(education != \u0026quot;Some secondary school\\nor less\u0026quot;) %\u0026gt;% group_by(senate_vote, education) %\u0026gt;% summarise_all(mean, na.rm = TRUE) %\u0026gt;% gather( key = \u0026quot;question\u0026quot;, value = \u0026quot;prop_correct\u0026quot;, -senate_vote, -education ) %\u0026gt;% mutate( question = factor( question, levels = QUESTION_ABBRS, labels = QUESTION_LABELS_SHORT ) ) responses_with_ed %\u0026gt;% ggplot( aes( reorder(question, -prop_correct), prop_correct, color = senate_vote ) ) + geom_hline(yintercept = 0.5, color = \u0026quot;white\u0026quot;, size = 2) + geom_line(aes(group = senate_vote)) + geom_point() + scale_color_manual( breaks = PARTY_LEVELS, values = PARTY_COLORS ) + scale_y_continuous( breaks = seq(0, 1, by = 0.1), labels = scales::percent_format(accuracy = 1) ) + theme( axis.text.x = element_text(size = 9, angle = 45, hjust = 1), legend.position = \u0026quot;top\u0026quot;, legend.title = element_blank() ) + labs( title = \u0026quot;Australians\u0026#39; Knowledge of Constitutional Issues by 2013 Senate Vote and Education Level\u0026quot;, subtitle = \u0026quot;University graduates outperform those less educated regardless of party affiliation\u0026quot;, caption = \u0026quot;Source: Australian Election Study 2016\u0026quot;, x = \u0026quot;Question Topic\u0026quot;, y = \u0026quot;Percentage of respondents who answered correctly\u0026quot; ) + facet_grid(cols = vars(education)) As we might’ve expected, the gap between voters across party preferences closes entirely with education level. Though it appears that accuracy amongst those with only a secondary school education does vary with party affiliation, this variation is much less pronounced amongst those with trade or other non-degree qualifications and completely indistinguishable amongst those with a university degree.\nI will certainly be continuing to explore this data. I’m excited to think more about why the variation remains amongst secondary school graduates, or perhaps how socioeconomic status comes into play. It would also be interesting to break down the Coalition into Liberal voters and National Party voters. I’ll also be looking into some longitudinal analysis with the AES data!\n ","date":1556496000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556496000,"objectID":"b5ecf25db2e47ec5375e2582b423ba52","permalink":"https://samrobertson.netlify.com/post/2019-04-29-auselectionpoll/","publishdate":"2019-04-29T00:00:00Z","relpermalink":"/post/2019-04-29-auselectionpoll/","section":"post","summary":"It’s not often I see a cool data project focused on Australia, and in particular Australian politics, so I was especially excited to see freerangestats’ exploration of the 2016 Australian Election Study featured in RWeekly this week!","tags":["R","data-visualization","tidyverse","improve-this-vis"],"title":"How Much Do Australians Know About Their Parliament?","type":"post"},{"authors":null,"categories":[],"content":"  This month I decided to take part in the Storytelling With Data monthly challenge for the first time! The dataset we were given to explore contains global aid exchanges between 47 countries across the world across the years 1973-2013. The goal is to create visualizations that answers the broad question: Who Donates?, as well as some bonus questions about distribution of donations geographically, temporally and by purpose of donation. Here’s my initial attempt! Along with some code. (The only package I use here is tidyverse).\nThe Data The data provided is nice and clean, so all we are left to do is read it in using read_csv(). I changed some variable names to make it nicer to work with, and noticed that there are a few negative quantities of money in the data, which I drop since they are impossible. Here’s a glimpse of what the data looks like:\n    id year donor recipient amount purpose_code purpose_desc    2414478 1977 Saudi Arabia India 348718518 23030 Power generation/renewable sources  2414509 1977 Saudi Arabia Brazil 191647004 23040 Electrical transmission/ distribution  2414635 1983 Saudi Arabia India 79371799 21030 Rail transport  2414665 1984 Saudi Arabia Taiwan 212202942 21030 Rail transport  2414667 1984 Saudi Arabia Korea 134511154 21040 Water transport  2414684 1985 Saudi Arabia India 128074768 23000 Energy generation and supply, combinations of activities     Who Donates? One of the challenges in answering this question is how to summarize across time. I chose to look at the proportion of the total money contributed to global aid that each country contributed and received.\ndonated \u0026lt;- data %\u0026gt;% group_by(donor) %\u0026gt;% summarise(donated = sum(amount)) %\u0026gt;% mutate(prop_donated = donated / sum(donated)) %\u0026gt;% select(country = donor, prop_donated) ## `summarise()` ungrouping output (override with `.groups` argument) received \u0026lt;- data %\u0026gt;% group_by(recipient) %\u0026gt;% summarise(received = sum(amount)) %\u0026gt;% mutate(prop_received = received / sum(received)) %\u0026gt;% select(country = recipient, prop_received) ## `summarise()` ungrouping output (override with `.groups` argument) aid \u0026lt;- donated %\u0026gt;% full_join(received, by = c(\u0026quot;country\u0026quot;)) %\u0026gt;% mutate_at(vars(-country), ~if_else(is.na(.), 0, .)) %\u0026gt;% gather(-country, key = direction, value = proportion_of_aid) %\u0026gt;% mutate(direction = str_extract(direction, \u0026quot;[^_]+$\u0026quot;)) country_order \u0026lt;- aid %\u0026gt;% spread(direction, proportion_of_aid) %\u0026gt;% mutate(diff = donated - received) %\u0026gt;% arrange(diff) %\u0026gt;% pull(country) aid \u0026lt;- aid %\u0026gt;% mutate(country = factor(country, levels = country_order, ordered = TRUE)) segments \u0026lt;- aid %\u0026gt;% spread(direction, proportion_of_aid) aid %\u0026gt;% ggplot(aes(y = country)) + geom_segment( aes(yend = country, x = donated, xend = received), color = \u0026quot;grey40\u0026quot;, data = segments ) + geom_point(aes(x = proportion_of_aid, color = direction), size = 2) + scale_y_discrete(expand = expand_scale(0)) + scale_x_sqrt( labels = scales::percent, expand = expand_scale(0), limits = c(0,0.4), breaks = c(0, 0.01, 0.025, 0.05, 0.1, 0.2, 0.3, 0.4) ) + scale_color_brewer(type = \u0026quot;qual\u0026quot;, palette = \u0026quot;Set1\u0026quot;, labels = str_to_title) + theme_minimal() + theme(legend.position = \u0026quot;top\u0026quot;) + coord_cartesian(clip = \u0026quot;off\u0026quot;) + labs( y = NULL, x = glue::glue(\u0026quot;Percentage of Total Aid {min(pull(data, year))} - {max(pull(data, year))}\u0026quot;), color = NULL, title = \u0026quot;The United States and Japan are the world\u0026#39;s major donors\u0026quot;, subtitle = \u0026quot;India has received almost 40% of all global aid\u0026quot; ) ## Warning: `expand_scale()` is deprecated; use `expansion()` instead. ## Warning: `expand_scale()` is deprecated; use `expansion()` instead. Excuse the squished y-axis. I played around with it for a while and eventually gave up. Any hints are very welcome!\n Has the Amount Donated Changed Over Time? In keeping with the same metric, proportion of aid contributed and received, we can also look at the trends over time. I’ve highlighted the top three donors and recipients in the figure. Interestingly, it seems that receiving tends to be steadier over time, while donations see more anomalous spikes\ndonated \u0026lt;- data %\u0026gt;% group_by(donor, year) %\u0026gt;% summarise(donated = sum(amount)) %\u0026gt;% ungroup() %\u0026gt;% mutate(prop_donated = donated / sum(donated)) %\u0026gt;% select(country = donor, year, prop_donated) ## `summarise()` regrouping output by \u0026#39;donor\u0026#39; (override with `.groups` argument) received \u0026lt;- data %\u0026gt;% group_by(recipient, year) %\u0026gt;% summarise(received = sum(amount)) %\u0026gt;% ungroup() %\u0026gt;% mutate(prop_received = received / sum(received)) %\u0026gt;% select(country = recipient, year, prop_received) ## `summarise()` regrouping output by \u0026#39;recipient\u0026#39; (override with `.groups` argument) timeseries \u0026lt;- donated %\u0026gt;% full_join(received, by = c(\u0026quot;country\u0026quot;, \u0026quot;year\u0026quot;)) %\u0026gt;% mutate_at(vars(prop_donated, prop_received), ~if_else(is.na(.), 0, .)) %\u0026gt;% gather(prop_donated, prop_received, key = direction, value = proportion) %\u0026gt;% mutate( proportion = if_else(direction == \u0026quot;prop_donated\u0026quot;, proportion, -proportion) ) top_3 \u0026lt;- aid %\u0026gt;% filter(direction == \u0026quot;donated\u0026quot;) %\u0026gt;% top_n(3, proportion_of_aid) %\u0026gt;% pull(country) bottom_3 \u0026lt;- aid %\u0026gt;% filter(direction == \u0026quot;received\u0026quot;) %\u0026gt;% top_n(3, proportion_of_aid) %\u0026gt;% pull(country) timeseries_main \u0026lt;- timeseries %\u0026gt;% filter(country %in% top_3 \u0026amp; direction == \u0026quot;prop_donated\u0026quot; | country %in% bottom_3 \u0026amp; direction == \u0026quot;prop_received\u0026quot;) country_order \u0026lt;- timeseries_main %\u0026gt;% filter(year == max(pull(data, year))) %\u0026gt;% arrange(desc(proportion)) %\u0026gt;% pull(country) timeseries_main \u0026lt;- timeseries_main %\u0026gt;% mutate(country = factor(country, levels = country_order, ordered = TRUE)) labeller \u0026lt;- function(y) { y = if_else(y \u0026lt; 0, -y, y) scales::percent(y) } timeseries %\u0026gt;% unite(group, country, direction, remove = FALSE) %\u0026gt;% ggplot(aes(year, proportion)) + geom_line(aes(group = group), alpha = 0.2) + geom_line(aes(color = country), data = timeseries_main) + scale_x_continuous(breaks = seq(1970, 2015, by = 5)) + scale_y_continuous(labels = labeller) + scale_color_brewer(type = \u0026quot;qual\u0026quot;, palette = \u0026quot;Dark2\u0026quot;) + theme_minimal() + labs( x = NULL, color = NULL, y = glue::glue(\u0026quot;Percentage of Annual Aid\u0026quot;), title = \u0026quot;Contributions from significant donors is not constant over time\u0026quot;, subtitle = \u0026quot;Major events like war and recession drive spikes in aid\u0026quot; ) + annotate( geom = \u0026quot;text\u0026quot;, x = 1974, y = 0.0275, label = \u0026quot;Proportion Donated\u0026quot;, hjust = 0 ) + annotate( geom = \u0026quot;text\u0026quot;, x = 1974, y = -0.0175, label = \u0026quot;Proportion Received\u0026quot;, hjust = 0 )  ","date":1552521600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552521600,"objectID":"4aa964349d629f5099e2c2a3c94a0dea","permalink":"https://samrobertson.netlify.com/post/2019-03-07-swdchallenge/","publishdate":"2019-03-14T00:00:00Z","relpermalink":"/post/2019-03-07-swdchallenge/","section":"post","summary":"This month I decided to take part in the Storytelling With Data monthly challenge for the first time! The dataset we were given to explore contains global aid exchanges between 47 countries across the world across the years 1973-2013.","tags":["R","data-visualization","tidyverse"],"title":"#SWDChallenge March 2019","type":"post"},{"authors":null,"categories":[],"content":"     As my senior year at Stanford nears the end, I’ve started to think more and more about what I’ve really learned here, and what I’ll be taking away from my undergraduate experience. Sure, there’s plenty of sappy stuff about coming of age and figuring out what I want to start doing with my life (spoiler: haven’t figured it out), but what about concrete knowledge I’ve gained from my classes. Being the data nerd that I am, I decided to take a “data-driven” approach to this question, and see what I could find. Here’s the results!\nlibrary(tidyverse) library(googlesheets) library(rvest) library(tidytext) library(wordcloud) library(tm) library(igraph) library(networkD3) FILE.googlesheets \u0026lt;- \u0026quot;~/Data/course-descriptions/myclasses.Rds\u0026quot; FILE.explorecourses \u0026lt;- \u0026quot;~/Data/course-descriptions/courses1819raw.Rds\u0026quot; Collating the data First, we need some data! Although I played around with trying to scrape my transcript, it proved not worth the effort with all the Stanford security, so I created a Google Sheets document and manually recorded each class I have taken, including the department code e.g. “CS”, the course code e.g. “106A”, the school e.g. “School of Engineering”, the number of units I took the class for, and the quarter I took the class (recorded as an integer from 1-12).\nThen I was able to use the googlesheets package to pull this data into R with only a few lines of code:\n# Log in to Google gs_auth(new_user = TRUE) # Find the document we want sheet_key \u0026lt;- gs_ls() %\u0026gt;% filter(sheet_title == \u0026quot;courses\u0026quot;) %\u0026gt;% pull(sheet_key) # Read the document df \u0026lt;- gs_key(sheet_key) %\u0026gt;% gs_read() To avoid authentication over and over, I saved the resulting dataframe, and we’ll use the saved version.\nclasses \u0026lt;- read_rds(FILE.googlesheets) head(classes) %\u0026gt;% knitr::kable()   dept code school units quarter    esf 6a Office of Vice Provost for Undergraduate Education 7 1  lawgen 116n Law School 3 1  math 51 School of Humanities \u0026amp; Sciences 5 1  cs 106a School of engineering 5 2  physics 41 School of Humanities \u0026amp; Sciences 4 2  physics 41a School of Humanities \u0026amp; Sciences 1 2    Let’s clean up the formatting a little first. We’ll also add a variable that contains just the numeric part of the course code, in case we want to look at how advanced the coursework is by the course number.\nclasses \u0026lt;- classes %\u0026gt;% mutate( dept = str_to_upper(dept), code = str_to_upper(code), school = str_to_title(school), code_numeric = parse_number(code) ) head(classes) %\u0026gt;% knitr::kable()   dept code school units quarter code_numeric    ESF 6A Office Of Vice Provost For Undergraduate Education 7 1 6  LAWGEN 116N Law School 3 1 116  MATH 51 School Of Humanities \u0026amp; Sciences 5 1 51  CS 106A School Of Engineering 5 2 106  PHYSICS 41 School Of Humanities \u0026amp; Sciences 4 2 41  PHYSICS 41A School Of Humanities \u0026amp; Sciences 1 2 41    Just with this data we can already do some cool analysis. For example, let’s look at the distribution of units over the course of my degree, divided by school…\ntotal_unit_count \u0026lt;- classes %\u0026gt;% group_by(quarter) %\u0026gt;% summarise(total_units = sum(units)) ## `summarise()` ungrouping output (override with `.groups` argument) fall_quarters \u0026lt;- tribble( ~quarter, ~label, 1, \u0026quot;2015-2016\u0026quot;, 4, \u0026quot;2016-2017\u0026quot;, 7, \u0026quot;2017-2018\u0026quot;, 10, \u0026quot;2018-2019\u0026quot; ) classes %\u0026gt;% group_by(school, quarter) %\u0026gt;% summarise(total_units = sum(units)) %\u0026gt;% ggplot(aes(quarter, total_units)) + geom_vline(aes(xintercept = quarter), data = fall_quarters, color = \u0026quot;grey90\u0026quot;) + geom_point(aes(group = school, color = school)) + geom_line(aes(group = school, color = school)) + geom_line(data = total_unit_count, color = \u0026quot;grey80\u0026quot;) + geom_text( aes(x = quarter + 0.2, label = label), y = 14, color = \u0026quot;grey40\u0026quot;, angle = 90, data = fall_quarters, hjust = 0 ) + theme( legend.position = \u0026quot;bottom\u0026quot;, legend.direction = \u0026quot;vertical\u0026quot;, axis.ticks.x = element_blank(), axis.text.x = element_blank() ) + labs( x = \u0026quot;Quarter\u0026quot;, y = \u0026quot;Units\u0026quot;, color = NULL, title = \u0026quot;Over Time I\u0026#39;ve started to take more classes in Engineering\\nand fewer in Humanities and Sciences\u0026quot; ) ## `summarise()` regrouping output by \u0026#39;school\u0026#39; (override with `.groups` argument) …what about by Department?\nclasses %\u0026gt;% group_by(school, dept) %\u0026gt;% summarise(total_units = sum(units)) %\u0026gt;% ggplot(aes(reorder(dept, total_units), total_units)) + geom_segment(aes(xend = dept, y = 0, yend = total_units), color = \u0026quot;grey60\u0026quot;) + geom_point(aes(color = school), size = 3) + scale_y_continuous(limits = c(0, 42), expand = c(0,0)) + theme_minimal() + theme( legend.position = \u0026quot;bottom\u0026quot;, legend.direction = \u0026quot;vertical\u0026quot; ) + coord_flip() + labs( x = NULL, y = \u0026quot;Total Units\u0026quot;, color = NULL, title = \u0026quot;Computer Science Dominates My Unit Count\u0026quot;, subtitle = \u0026quot;Math, MS\u0026amp;E and Statistics classes are also required of my major\u0026quot; ) ## `summarise()` regrouping output by \u0026#39;school\u0026#39; (override with `.groups` argument)  Scraping Course Descriptions What I am really curious about, though, is whether we can see any themes in my interests from the course descriptions of the classes I’ve taken, as listed in Explore Courses. I wasn’t about to copy and paste all of these by hand, plus this was a great opportunity to practice web scraping with rvest!\nI scraped ALL of the course descriptions from every page of Explore Courses, so that I can join the descriptions to my dataframe of classes. This took an hour or so to run, but I made sure to save the result!\nexplore_courses \u0026lt;- read_rds(FILE.explorecourses) head(explore_courses) ## # A tibble: 6 x 4 ## num title desc attrs ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 AA 47… Why Go To Space? \u0026quot;Why do we spend billions… \u0026quot;\\r\\n\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t… ## 2 AA 93: Building Trust i… \u0026quot;Preparatory course for B… \u0026quot;\\r\\n\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t… ## 3 AA 10… Introduction to … \u0026quot;This class introduces th… \u0026quot;\\r\\n\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t… ## 4 AA 10… Introduction to … \u0026quot;This course explores the… \u0026quot;\\r\\n\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t… ## 5 AA 10… Air and Space Pr… \u0026quot;This course is designed … \u0026quot;\\r\\n\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t… ## 6 AA 10… Surviving Space \u0026quot;Space is dangerous. Anyt… \u0026quot;\\r\\n\\t\\t\\t\\t\\t\\r\\n\\t\\t\\t… Clearly, the results are a little messy! For now, though all we want is the description to join to the datafram of my classes, and maybe the title of the classes might be fun too. To join to our dataset we need to split the num variable into department and code. While we’re at it, let’s drop any prerequisites from the desc variable. We don’t care about them for analysing the descriptions.\nexplore_courses \u0026lt;- explore_courses %\u0026gt;% mutate(num = str_extract(num, \u0026quot;^[^:]*\u0026quot;)) %\u0026gt;% separate(num, into = c(\u0026quot;dept\u0026quot;, \u0026quot;code\u0026quot;), sep = \u0026quot; \u0026quot;, extra = \u0026quot;merge\u0026quot;) %\u0026gt;% mutate(dept = str_to_upper(dept), code = str_to_upper(code)) %\u0026gt;% separate( desc, into = c(\u0026quot;desc\u0026quot;), sep = \u0026quot;(Prerequisites:|Prerequisite:|prerequisite:|prerequisites:)\u0026quot;, extra = \u0026quot;drop\u0026quot; ) %\u0026gt;% select(dept, code, title, desc) head(explore_courses, 2) %\u0026gt;% knitr::kable()     dept code title desc    AA 47SI Why Go To Space? Why do we spend billions of dollars exploring space? What can modern policymakers, entrepreneurs, and industrialists do to help us achieve our goals beyond planet Earth? Whether it is the object of exploration, science, civilization, or conquest, few domains have captured the imagination of a species like space. This course is an introduction to space policy issues, with an emphasis on the modern United States. We will present a historical overview of space programs from all around the world, and then spend the last five weeks discussing present policy issues, through lectures and guest speakers from NASA, the Department of Defense, new and legacy space industry companies, and more. Students will present on one issue that piques their interest, selecting from various domains including commercial concerns, military questions, and geopolitical considerations.  AA 93 Building Trust in Autonomy Preparatory course for Bing Overseas Studies summer course in Edinburgh.    That looks better!!\nNow we can join this to classes:\nclasses_with_descriptions \u0026lt;- classes %\u0026gt;% left_join(explore_courses, by = c(\u0026quot;dept\u0026quot;, \u0026quot;code\u0026quot;)) Even in the first few results, there are some NA values resulting from the join. A concern is that the matching of dept and code isn’t working due to a formatting quirk. Sadly, it’s even worse… Explore Courses deletes classes after they haven’t been offered for a while!\nclasses_with_descriptions %\u0026gt;% filter(is.na(desc)) %\u0026gt;% knitr::kable()   dept code school units quarter code_numeric title desc    LAWGEN 116N Law School 3 1 116 NA NA  PHYSICS 41A School Of Humanities \u0026amp; Sciences 1 2 41 NA NA  THINK 52 Office Of Vice Provost For Undergraduate Education 4 2 52 NA NA  CS 41 School Of Engineering 2 6 41 NA NA  CS 193X School Of Engineering 3 6 193 NA NA  ECON 5 School Of Humanities \u0026amp; Sciences 1 11 5 NA NA    Most of these are classes I took a while ago, and most are for few units, so excluding these from analysis of descriptions shouldn’t be a big deal!\n Analysing Course Descriptions Now we get to the fun part! The code in this section is adapted from this awesome blog post by Juan Orduz analyzing tweet data.\nLet’s start with something easy and classic, a wordcloud! For this we can use the packages tidytext to help with counting words, and wordcloud for visualization.\nclasses_with_descriptions %\u0026gt;% unnest_tokens(word, desc) %\u0026gt;% anti_join(get_stopwords()) %\u0026gt;% mutate(word = str_extract(word, \u0026quot;[:alpha:]+\u0026quot;)) %\u0026gt;% count(word) %\u0026gt;% arrange(desc(n)) %\u0026gt;% with( wordcloud( word, n, min.freq = 5, random.order = FALSE, colors = brewer.pal(8, \u0026#39;Dark2\u0026#39;) ) ) ## Joining, by = \u0026quot;word\u0026quot; No surprises here! But it’s still fun to see my degree described in pretty colored words.\nWhat is perhaps most interesting to me is whether we can see relationships between topics in the course descriptions! For this, I used the igraph package to create a graph, and the networkD3 package for visualization with D3.\nFirst we use tidytext to count the bigrams, the pairs of words that occur next to each other, in the descriptions.\nword_bigrams \u0026lt;- classes_with_descriptions %\u0026gt;% unnest_tokens( input = desc, output = bigram, token = \u0026#39;ngrams\u0026#39;, n = 2 ) %\u0026gt;% filter(!is.na(bigram)) %\u0026gt;% separate(col = bigram, into = c(\u0026#39;word1\u0026#39;, \u0026#39;word2\u0026#39;), sep = \u0026#39; \u0026#39;) %\u0026gt;% select(word1, word2) bigram_count \u0026lt;- word_bigrams %\u0026gt;% count(word1, word2, sort = TRUE) Now we can create a graph object and use the base R (gasp) plot function to visualize the relationships between words. We use a threshold to include only bigrams that occur more times than the threshold. It turns out that 2 is a good threshold for this dataset.\nthreshold \u0026lt;- 2 network \u0026lt;- bigram_count %\u0026gt;% filter(n \u0026gt; threshold) %\u0026gt;% graph_from_data_frame(directed = FALSE) plot( network, vertex.size = 1, vertex.label.color = \u0026#39;black\u0026#39;, vertex.label.cex = 0.7, vertex.label.dist = 1, edge.color = \u0026#39;gray\u0026#39;, main = \u0026#39;Course Descriptions\u0026#39;, alpha = 50 ) Even restricting the graph to bigrams that occur at least 3 times, it’s still hard to really see the relationships here. Now’s when we use D3 to take this visualization to the next level. Since there’s so much more interaction possible with a D3 graph, we’ll lower the threshold to see a little more detail.\nthreshold \u0026lt;- 1 network \u0026lt;- bigram_count %\u0026gt;% filter(n \u0026gt; threshold) %\u0026gt;% graph_from_data_frame(directed = FALSE) network_D3 \u0026lt;- igraph_to_networkD3(network) network_D3$nodes \u0026lt;- network_D3$nodes %\u0026gt;% mutate( degree = 10 * degree(network), group = 1 ) network_D3$links \u0026lt;- network_D3$links %\u0026gt;% mutate(width = 10 * E(network)$n / max(E(network)$n)) forceNetwork( Links = network_D3$links, Nodes = network_D3$nodes, Source = \u0026#39;source\u0026#39;, Target = \u0026#39;target\u0026#39;, NodeID = \u0026#39;name\u0026#39;, Group = \u0026#39;group\u0026#39;, opacity = 0.9, Value = \u0026#39;width\u0026#39;, Nodesize = \u0026#39;degree\u0026#39;, linkWidth = JS(\u0026quot;function(d) { return Math.sqrt(d.value); }\u0026quot;), fontSize = 12, zoom = TRUE, opacityNoHover = 1 )  {\"x\":{\"links\":{\"source\":[58,81,2,5,25,11,36,2,10,0,3,8,17,36,20,0,20,1,20,36,28,21,2,38,13,6,11,50,84,7,33,36,28,67,1,29,1,1,102,2,2,1,36,4,7,5,12,1,2,1,0,2,35,106,11,2,14,28,28,1,5,1,1,54,83,36,1,11,5,48,0,57,36,1,36,19,2,20,2,1,1,36,1,16,36,12,4,46,2,11,66,20,1,33,1,1,108,20,7,32,2,0,2,7,20,1,2,91,2,20,115,1,110,38,36,26,26,1,30,1,89,2,1,8,5,60,90,0,111,82,72,48,2,36,20,18,66,98,13,112,1,2,2,2,1,36,2,17,14,55,36,1,2,0,2,18,95,20,77,23,17,2,20,31,15,7,38,1,10,51,25,28,2,26,20,23,11,18,15,0,5,1,93,2,20,39,0,1,11,3,7,93,61,34,98,51,17,7,5,38,13,40,42,115,93],\"target\":[133,141,38,38,38,38,39,22,118,138,13,13,40,41,41,42,42,42,43,44,44,44,45,47,47,47,14,117,117,117,49,49,50,136,145,122,51,146,146,24,24,52,52,15,15,15,16,147,17,17,53,53,159,157,150,55,56,121,137,59,8,18,18,132,132,60,25,25,25,61,62,63,63,64,64,65,27,28,28,68,29,69,69,70,70,70,71,126,72,73,73,30,74,75,75,9,158,31,31,76,76,78,78,79,80,10,10,152,32,164,166,82,160,124,85,86,135,87,87,148,143,88,149,11,11,91,144,139,162,142,92,92,119,93,94,134,95,156,96,163,97,97,99,125,100,161,101,101,103,103,104,104,105,34,120,107,155,165,140,127,130,108,108,35,35,35,109,109,128,128,36,36,36,36,36,36,36,36,36,36,36,36,153,19,112,113,4,4,151,20,12,114,114,123,123,129,131,37,21,115,115,115,115,116,154],\"value\":[10,9.09090909090909,8.18181818181818,8.18181818181818,8.18181818181818,7.27272727272727,5.45454545454545,5.45454545454545,4.54545454545455,4.54545454545455,4.54545454545455,4.54545454545455,4.54545454545455,3.63636363636364,3.63636363636364,3.63636363636364,3.63636363636364,3.63636363636364,3.63636363636364,3.63636363636364,3.63636363636364,3.63636363636364,3.63636363636364,3.63636363636364,3.63636363636364,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,2.72727272727273,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182,1.81818181818182],\"colour\":[\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\",\"#666\"]},\"nodes\":{\"name\":[\"in\",\"of\",\"and\",\"introduction\",\"this\",\"is\",\"such\",\"will\",\"emphasis\",\"laws\",\"linear\",\"on\",\"topics\",\"an\",\"based\",\"course\",\"covered\",\"data\",\"engineering\",\"theory\",\"to\",\"what\",\"abstraction\",\"at\",\"concepts\",\"focus\",\"for\",\"historical\",\"how\",\"image\",\"interest\",\"learn\",\"machine\",\"programming\",\"several\",\"students\",\"the\",\"we\",\"a\",\"about\",\"analysis\",\"answers\",\"applications\",\"approaches\",\"are\",\"art\",\"artificial\",\"as\",\"by\",\"c\",\"can\",\"computer\",\"context\",\"demonstrations\",\"differential\",\"discussion\",\"discussions\",\"drawn\",\"ee\",\"elements\",\"first\",\"fostered\",\"freedom\",\"from\",\"future\",\"graph\",\"group\",\"health\",\"ideas\",\"implications\",\"include\",\"initiative\",\"interaction\",\"interactive\",\"knowledge\",\"language\",\"learning\",\"least\",\"lecture\",\"lectures\",\"limited\",\"math\",\"mathematics\",\"maxwell's\",\"may\",\"modeling\",\"models\",\"mutual\",\"networks\",\"neural\",\"object\",\"order\",\"peer\",\"physical\",\"preference\",\"problem\",\"provides\",\"race\",\"random\",\"reading\",\"role\",\"science\",\"scientific\",\"sections\",\"seeds\",\"sets\",\"skills\",\"software\",\"student\",\"subject\",\"symmetric\",\"their\",\"these\",\"thinking\",\"understanding\",\"with\",\"working\",\"be\",\"algebra\",\"performance\",\"social\",\"do\",\"classification\",\"variables\",\"matrix\",\"research\",\"intelligence\",\"stanford\",\"systems\",\"vision\",\"structures\",\"visualization\",\"equations\",\"103\",\"principles\",\"more\",\"care\",\"does\",\"america\",\"our\",\"squares\",\"104\",\"particularly\",\"network\",\"oriented\",\"change\",\"computing\",\"cs106a\",\"nature\",\"objects\",\"developing\",\"time\",\"logic\",\"theories\",\"world\",\"solving\",\"processes\",\"developed\",\"leaders\",\"develop\",\"matrices\",\"same\",\"own\",\"questions\",\"make\",\"sophomores\",\"mathematical\"],\"group\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"nodesize\":[90,290,260,20,40,70,10,70,30,10,40,90,30,50,30,50,20,60,50,20,140,20,10,20,20,50,30,10,70,20,20,30,20,20,20,40,260,10,80,20,20,20,40,10,30,10,10,30,20,20,20,30,20,20,10,20,10,10,10,10,20,20,10,20,20,10,20,10,10,20,30,10,20,20,10,20,20,10,20,10,10,10,20,10,10,10,10,20,10,10,10,20,20,40,10,20,10,20,20,10,10,20,10,20,20,10,10,10,30,20,10,10,20,10,20,60,10,30,10,10,10,10,10,20,10,10,10,10,20,10,10,10,20,10,10,10,10,10,10,10,10,10,10,10,10,10,20,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10]},\"options\":{\"NodeID\":\"name\",\"Group\":\"group\",\"colourScale\":\"d3.scaleOrdinal(d3.schemeCategory20);\",\"fontSize\":12,\"fontFamily\":\"serif\",\"clickTextSize\":30,\"linkDistance\":50,\"linkWidth\":\"function(d) { return Math.sqrt(d.value); }\",\"charge\":-30,\"opacity\":0.9,\"zoom\":true,\"legend\":false,\"arrows\":false,\"nodesize\":true,\"radiusCalculation\":\" Math.sqrt(d.nodesize)+6\",\"bounded\":false,\"opacityNoHover\":1,\"clickAction\":null}},\"evals\":[],\"jsHooks\":[]} It’s so much fun to play around with the D3 graph visualization. Hover over nodes to read the labels more clearly. Unsurprisingly, the words cluster around the three nodes: “and”, “the” and “of”, which makes it more difficult to see relationships between domain terms. It’s fun to look at the bigrams that aren’t part of the main connected component, like “machine learning”, “maxwell’s differential equations”, “health care” and “neural networks”. Again, not surprising but kind of cute.\n ","date":1551312000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551312000,"objectID":"55db57bede7cc999f714cd6f50f4bd11","permalink":"https://samrobertson.netlify.com/post/2019-02-28-visualizing-course-descriptions/","publishdate":"2019-02-28T00:00:00Z","relpermalink":"/post/2019-02-28-visualizing-course-descriptions/","section":"post","summary":"As my senior year at Stanford nears the end, I’ve started to think more and more about what I’ve really learned here, and what I’ll be taking away from my undergraduate experience.","tags":["R","data-visualization","text-analysis","D3","tidyverse"],"title":"Visualizing Course Descriptions","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://samrobertson.netlify.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Pavan Mehrotra","Sabar Dasgupta","Samantha Robertson","Paul Nuyujukian"],"categories":null,"content":"","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522540800,"objectID":"ba1c9cce084e67e2bac2ff2ed0abf554","permalink":"https://samrobertson.netlify.com/publication/licorice/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/licorice/","section":"publication","summary":"Systems neuroscience studies involving in-vivo models often require realtime data processing. In these studies, many events must be monitored and processed quickly, including behavior of the subject (e.g., movement of a limb) or features of neural data (e.g., a neuron transmitting an action potential). Unfortunately, most realtime platforms are proprietary, require specific architectures, or are limited to low-level programming languages. Here we present a hardware-independent, open-source realtime computation platform that supports high-level programming. The resulting platform, LiCoRICE, can process on order 10e10 bits/sec of network data at 1 ms ticks with 18.2 µs jitter. It connects to various inputs and outputs (e.g., DIO, Ethernet, database logging, and analog line in/out) and minimizes reliance on custom device drivers by leveraging peripheral support via the Linux kernel. Its modular architecture supports model-based design for rapid prototyping with C and Python/Cython and can perform numerical operations via BLAS/LAPACKoptimized NumPy that is statically compiled via Numba’s pycc. LiCoRICE is not only suitable for systems neuroscience research, but also for applications requiring closed-loop realtime data processing from robotics and control systems to interactive applications and quantitative financial trading.","tags":["licorice","neuroscience","software","realtime"],"title":"An Open-Source Realtime Computation Platform (Short WIP Paper)","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://samrobertson.netlify.com/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://samrobertson.netlify.com/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]